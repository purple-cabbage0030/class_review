1. ELK 설치
    다운로드
    압축 해제
    directory 이름 축소

    ElasticSearch(ES) bin > elasticsearch.bat 실행
    브라우저 접속 확인 http://127.0.0.1:9200
        - 버전, 실행 pc 이름, etc.
    
    kibana bin > kibana.bat 실행
        - ES가 실행된 상태여야만 정상 실행됨
        - 브라우저 접속 확인 http://localhost:5601 -> Dev Tools에서 crud 작업

2. 두 솔루션의 구동 원리
    1) json 형식으로 저장
        - 저장 작업 명령은 kibana에서 함
        - 저장은 ES에 됨.

    2) postman으로 crud 작업 시 url
        http://127.0.0.1:9200으로 접속해야 함 (db에 접속해야 하기 때문...)

3. JSON 저장 구조
    1) REST API 관점에서 CRUD
    
    POST hello_index/_doc/1   ==>  방식 table명/_doc/데이터구분을위한primarykey
    {                         ==> json 포맷의 데이터 구조
    "message" : "힙합",       ==> message를 key로 밸류 저장 및 수정 의미
    "name" : "NAS"
    }

    postman 사용 시 request 정보 구성에 있어서 json 포맷 설정 필수

4. 모르고 하는 crud
    1) 제공 데이터
    {"employees":[
        { "firstName":"John", "lastName":"Doe" },
        { "firstName":"Anna", "lastName":"Smith" },
        { "firstName":"Peter", "lastName":"Jones" }
    ]}

    2) 저장 -> 검색 - > 수정 -> 검색 - > 삭제 -> 검색

    POST _bulk
    { "index" : { "_index" : "employees", "_id" : "1" } }
    { "firstName":"John", "lastName":"Doe" }
    { "index" : { "_index" : "employees", "_id" : "2" } }
    { "firstName":"Anna", "lastName":"Smith" }
    { "index" : { "_index" : "employees", "_id" : "3" } }
    { "firstName":"Peter", "lastName":"Jones" }
    GET employees
    GET employees/_search/?q=Smith

    - ES: 대용량 데이터를 빠르게 검색 및 활용 가능하게 하는 엔진이 내장되어 있음
    대용량 데이터는 사용자들이 crud
    해당 문법은 json 포맷이기만 하면 다 허용 (정형 구조가 아님)
    단 db의 sql처럼 ES에서도 명확하게 구분해야 하는 것들 있음
        : ES 자체적인 문법 학습
        : REST API로 구현된 구조

    - 대용량 데이터를 한 번에 ES에 저장하기 위한 문법
    POST _bulk

    - "_index" : "employees": table명이 employees
    - "_id" : "1" : id라는 컬럼에 pk값으로 1을 저장함을 의미
    - _id: ES에서 중복되지 않는 데이터 컬럼 의미

    index라는 key로 테이블과 id값 설정
    하나의 row 값을 설정
    { "index" : { "_index" : "테이블명", "_id" : "pk값" } }

    이미 존재하는 employees table에 id 컬럼이 1인 row값으로 저장하고자 하는 데이터값들
    { "firstName":"John", "lastName":"Doe" }

5. ES 특징
    1) 문법 오류가 없는 json 데이터만 저장
        table이라는 index가 생성됨
        각 데이터에 적합한 field의 타입이 자동 적용(text/long/...)
        저장 데이터가 하나의 row로 자동 저장

    2) 초반 table 생성처럼 각 field별로 타입 지정 후에 데이터 저장도 가능
    * RDBMS 특징: 테이블 생성이 되어야만 데이터 저장 가능

6. review
    1) kibana dev tool
    2) postman
    3) elasticsearch-head - 크롬의 확장 플러그인
        실시간 데이터 확인 및 활용 권장
    4) curl - 도스창 명령어로 crud 작업 가능함