학습 내용

1. index pattern 형식으로 키바나에서 다양한 시각화 등 사용을 위한 기본 설정:
    시계열 데이터(시간을 기준으로 데이터 분석)
    timestamp 포맷으로 형성하는 새로운 field 구성
    convert_date: 가변적인 사용자 정의 이름, 날짜시분초를 표현하는 field 값으로 새롭게 생성
    date field 값으로부터 가공해서 파생

2. Pipeline 구성 시 필수
    1) 자동화
    2) 실시간 데이터를 크롤링해서 매일 파일로 생성
    3) 매일 파일이 다른 파일명으로 구성 시
        - file 명 권장 포맷: 가급적 날짜 포함
    4) 언제 크롤링 수행할지 자동화
        - crawling.py 파일을 특정 시간에 실행되도록 설정
        - python 쿼츠 / python 스케줄러

    5) 미션
        소스 분석 & 자동으로 파일 실행되게 개발
        - 모니터링 주기: 1일 1회, 오후 11시

* 중간 프로젝트
    python - flask : 웹 브라우저로 요청/응답 처리 가능
            - rest api
            - RDBMS & ELK - MySQL...
    html / css / javascript(비동기)
    github 활용 권장
    aws로 배포
