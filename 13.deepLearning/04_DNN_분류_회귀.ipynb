{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data 모듈\n",
    "- 데이터 입력 파이프라인을 위한 모듈\n",
    "    - 모델 학습/평가을 위한 대용량 데이터셋을 제공(feeding)하기 위한 모듈\n",
    "    - raw dataset 에서 입력을 위한 전처리, 제공을 위한 배치, shuffling등을 한번에 처리할 수 있게 한다.\n",
    "- tf.data.Dataset 추상클래스에서 상속된 여러가지 클래스들을 제공\n",
    "    - 입력 소스의 제공 형태에 따라 다양한 방식을 제공\n",
    "\n",
    "\n",
    "## 데이터셋 API 사용\n",
    "1. <span style='font-size:1.2em;font-weight:bolder'>Dataset 생성</span>\n",
    "    - raw dataset을 지정\n",
    "    - from_tensor_slices(), from_generator() 클래스 메소드, tf.data.TFRecordDataset 클래스 등을 사용해 메모리나 파일에 있는 데이터를 Dataset으로 만든다.\n",
    "    - from_tensor_slices(): 리스트 넘파이배열, 텐서플로 자료형에서 데이터를 생성한다.\n",
    "2. <span style='font-size:1.2em;font-weight:bolder'>제공 데이터 전처리</span>\n",
    "    - map(함수) : 하나 하나의 데이터를 변환\n",
    "        - 함수: 값을 변환할 함수로 입력데이터셋의 개수만큼 매개변수 선언\n",
    "    - filter(함수): 특정 조건의 데이터만 제공하도록 처리.\n",
    "        - 함수: 제공할 값의 조건을 정의한 함수로 입력데이터셋의 개수만큼 매개변수 선언하고 bool 값을 반환.\n",
    "3. <span style='font-size:1.2em;font-weight:bolder'>Dataset을 사용해 데이터 제공</span>\n",
    "    - batch(), shuffle()을 이용해 제공 방식 지정\n",
    "        - batch(size): 학습/평가시 한번에 제공할 batch size 지정\n",
    "            - size: int. batch size 지정\n",
    "            - drop_remainder: bool. True일 경우 마지막 제공시 남은 데이터수가 batch size보다 작으면 제공하지 않는다.\n",
    "    -  shuffle(buffer 크기): dataset의 원소들의 순서를 섞는다. \n",
    "        - buffer 크기: int. buffer 크기는 섞는 공간의 크기로  **데이터보다 크거나 같으면** 완전셔플, **적으면 일부만 가져와서 섞어** 완전셔플이 안된다.\n",
    "        - 데이터 사이즈가 너무 커서 메모리가 부족할 경우 버퍼크기를 적게 준다.\n",
    "        - 메모리가 충분하다면 데이터의 개수와 동일하게 주면된다.\n",
    "    - repeat(count): 전체 데이터를 한번 다 제공한 뒤 다시 데이터를 제공한다.\n",
    "        - count: 몇번 제공할지 반복 횟수\n",
    "        - shuffle이 적용된 Dataset의 경우 다음 반복 제공마다 shuffle을 진행한다.\n",
    "        \n",
    "### Dataset 메소드\n",
    "- take(개수): 지정한 개수만큼의 데이터만 제공한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = np.arange(10)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(raw_data)\n",
    "# 데이터셋 객체 생성 함수 - raw data 타입에 따라 바뀜. 메모리에 있는 건 fromtensorslicses 사용\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Dataset으로부터 값 조회\n",
    "# take() 함수 사용 or 반복문 이용 (Dataset => iterable 타입)\n",
    "for data in dataset:\n",
    "    print(data)   # tensorflow의 배열 타입 - ndarray랑 거의 비슷하다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data2 = np.arange(10, 20)\n",
    "raw_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32) tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32) tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32) tf.Tensor(13, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32) tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32) tf.Tensor(15, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32) tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32) tf.Tensor(17, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32) tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32) tf.Tensor(19, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 학습 - model.fit(X, y) - X_train과 y_train 묶어줌!!\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices((raw_data, raw_data2))\n",
    "for X, y in dataset2:\n",
    "#     print(data)   # 같은 인덱스의 값들이 tuple로 묶여서 반환됨\n",
    "#     print(type(data))\n",
    "    print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.take(개수): 지정한 개수만큼 dataset에서 조회\n",
    "dataset3 = dataset.take(3)\n",
    "print(type(dataset3))   # TakeDataset\n",
    "for data in dataset3:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ShuffleDataset'>\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.shuffle(buffer_size:정수): dataset의 원소들을 섞어줌. buffer size는 메모리가 허용하는 한 raw_data와 같은 개수로 지정\n",
    "dataset4 = dataset.shuffle(10)\n",
    "print(type(dataset4))   # ShuffleDataset\n",
    "for data in dataset4:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "tf.Tensor([0 1 2], shape=(3,), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# dataset.batch(batch_size): 한번에 제공하는 데이터의 개수\n",
    "dataset5 = dataset.batch(3)\n",
    "print(type(dataset5))   # BatchDataset\n",
    "for data in dataset5:\n",
    "    print(data)\n",
    "    print(type(data))  # EagerTensor\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([6 9 8], shape=(3,), dtype=int32)\n",
      "tf.Tensor([7 0 5], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3 2 4], shape=(3,), dtype=int32)\n",
      "tf.Tensor([1], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "d = dataset.shuffle(10).batch(3)\n",
    "for data in d:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.RepeatDataset'>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.repeat(count): 전체 데이터셋을 count만큼 반복해서 제공, count 생략하면 무한제공\n",
    "dataset7 = dataset.repeat(3)\n",
    "print(type(dataset7))   # RepeatDataset\n",
    "for data in dataset7:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 0 6 7 9], shape=(5,), dtype=int32)\n",
      "tf.Tensor([4 5 8 3 1], shape=(5,), dtype=int32)\n",
      "tf.Tensor([1 5 9 0 3], shape=(5,), dtype=int32)\n",
      "tf.Tensor([6 4 2 8 7], shape=(5,), dtype=int32)\n",
      "tf.Tensor([8 6 9 2 4], shape=(5,), dtype=int32)\n",
      "tf.Tensor([5 1 0 7 3], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset8 = dataset.shuffle(10).batch(5).repeat(3)\n",
    "for data in dataset8:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(36, shape=(), dtype=int32)\n",
      "tf.Tensor(49, shape=(), dtype=int32)\n",
      "tf.Tensor(64, shape=(), dtype=int32)\n",
      "tf.Tensor(81, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.map(함수): 원소의 값을 함수로 변환해서 제공. 매개변수: dataset이 제공하는 값을 받는 변수, 반환값: dataset이 제공하는 값\n",
    "# 값들을 제곱해서 반환\n",
    "# mapping함수 - 입력 데이터(argument)와 출력 데이터(return)의 데이터 타입이 동일해야 한다\n",
    "def mapping_func(x):\n",
    "    return x**2\n",
    "\n",
    "dataset9 = dataset.map(mapping_func)\n",
    "print(type(dataset9))\n",
    "\n",
    "for data in dataset9:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=10>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=11>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=8>, <tf.Tensor: shape=(), dtype=int32, numpy=12>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=27>, <tf.Tensor: shape=(), dtype=int32, numpy=13>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=64>, <tf.Tensor: shape=(), dtype=int32, numpy=14>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=125>, <tf.Tensor: shape=(), dtype=int32, numpy=15>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=216>, <tf.Tensor: shape=(), dtype=int32, numpy=16>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=343>, <tf.Tensor: shape=(), dtype=int32, numpy=17>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=512>, <tf.Tensor: shape=(), dtype=int32, numpy=18>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=729>, <tf.Tensor: shape=(), dtype=int32, numpy=19>)\n"
     ]
    }
   ],
   "source": [
    "def mapping_func2(x, y):   # x = raw data, y = raw data2\n",
    "    return x**3, y # y 처리하지 않더라도 무조건 반환\n",
    "\n",
    "dataset10 = dataset2.map(mapping_func2)\n",
    "\n",
    "for data in dataset10:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 람다(표현)식: 함수를 연삭 식으로 정의. lambda 매개변수들: 반환값\n",
    "test2 = lambda x: x + 10\n",
    "test2(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3 = lambda x, y: (x+10, y*2)\n",
    "test3(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(36, shape=(), dtype=int32)\n",
      "tf.Tensor(49, shape=(), dtype=int32)\n",
      "tf.Tensor(64, shape=(), dtype=int32)\n",
      "tf.Tensor(81, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset11 = dataset.map(lambda x: x**2)\n",
    "for d in dataset11:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=100>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=121>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=8>, <tf.Tensor: shape=(), dtype=int32, numpy=144>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=27>, <tf.Tensor: shape=(), dtype=int32, numpy=169>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=64>, <tf.Tensor: shape=(), dtype=int32, numpy=196>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=125>, <tf.Tensor: shape=(), dtype=int32, numpy=225>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=216>, <tf.Tensor: shape=(), dtype=int32, numpy=256>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=343>, <tf.Tensor: shape=(), dtype=int32, numpy=289>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=512>, <tf.Tensor: shape=(), dtype=int32, numpy=324>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=729>, <tf.Tensor: shape=(), dtype=int32, numpy=361>)\n"
     ]
    }
   ],
   "source": [
    "dataset12 = dataset2.map(lambda x, y: (x**3, y**2))\n",
    "for d in dataset12:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.FilterDataset'>\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# dataset.filter(함수): 원소들 중에서 특정 조건이 true인 값들만 제공\n",
    "# 함수- 매개변수: dataset이 제공하는 값을 받을 변수 (dataset의 배열개수만큼 지정), 반환값은 불리언\n",
    "# 원소들 중에서 2의 배수만 제공하는 dataset\n",
    "def filter_func(x):\n",
    "    return x%2 == 0    # x가 2의 배수인 경우 True 반환\n",
    "\n",
    "dataset13 = dataset.filter(filter_func)\n",
    "print(type(dataset13))\n",
    "for d in dataset13:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset14 = dataset.filter(lambda x : x > 5)\n",
    "for d in dataset14:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000015A36F18940> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000015A36F18940>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: (x + 10))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: (x >= 0))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000015A36F18940> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000015A36F18940>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: (x + 10))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: (x >= 0))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000015A36F185E0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000015A36F185E0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: (x + 10))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: (x >= 0))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000015A36F185E0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000015A36F185E0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: (x + 10))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: (x >= 0))\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor([10 13 17], shape=(3,), dtype=int32)\n",
      "tf.Tensor([19 16 14], shape=(3,), dtype=int32)\n",
      "tf.Tensor([12 18 11], shape=(3,), dtype=int32)\n",
      "tf.Tensor([15 20], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "raw_data = np.arange(-10,11)\n",
    "dataset_final = tf.data.Dataset.from_tensor_slices(raw_data).filter(lambda x:x>=0).map(lambda x:x+10).shuffle(raw_data.size).batch(3)\n",
    "for d in dataset_final:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 회귀 - Boston Housing Dataset\n",
    "보스턴 주택가격 dataset은 다음과 같은 속성을 바탕으로 해당 타운 주택 가격의 중앙값을 예측하는 문제.\n",
    "- CRIM: 범죄율\n",
    "- ZN: 25,000 평방피트당 주거지역 비율\n",
    "- INDUS: 비소매 상업지구 비율\n",
    "- CHAS: 찰스강에 인접해 있는지 여부(인접:1, 아니면:0)\n",
    "- NOX: 일산화질소 농도(단위: 0.1ppm)\n",
    "- RM: 주택당 방의 수\n",
    "- AGE: 1940년 이전에 건설된 주택의 비율\n",
    "- DIS: 5개의 보스턴 직업고용센터와의 거리(가중 평균)\n",
    "- RAD: 고속도로 접근성\n",
    "- TAX: 재산세율\n",
    "- PTRATIO: 학생/교사 비율\n",
    "- B: 흑인 비율\n",
    "- LSTAT: 하위 계층 비율\n",
    "\n",
    "예측해야하는 것\n",
    "- MEDV: 타운의 주택가격 중앙값(단위: 1,000달러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers, models   # layers: Deeplearning 모델의 Layer를 정의하는 클래스들을 가진 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤값들의 seed값 지정\n",
    "np.random.seed(0)\n",
    "tf.random_set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,), (102, 13), (102,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 로딩\n",
    "(train_X, train_y), (test_X, test_y) = keras.datasets.boston_housing.load_data()\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, 0.00000e+00, 5.38000e-01,\n",
       "        6.14200e+00, 9.17000e+01, 3.97690e+00, 4.00000e+00, 3.07000e+02,\n",
       "        2.10000e+01, 3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, 0.00000e+00, 4.15000e-01,\n",
       "        7.61000e+00, 1.57000e+01, 6.27000e+00, 2.00000e+00, 3.48000e+02,\n",
       "        1.47000e+01, 3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, 0.00000e+00, 6.31000e-01,\n",
       "        4.97000e+00, 1.00000e+02, 1.33250e+00, 2.40000e+01, 6.66000e+02,\n",
       "        2.02000e+01, 3.75520e+02, 3.26000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터, 변수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "LEARNING_RATE = 0.001    # 학습률\n",
    "N_EPOCHS = 200   # epoch 수 (fit 할 때 데이터를 몇 번 넣을지) 에폭 너무 많으면 과대적합 너무 적으면 과소적합\n",
    "N_BATCHS = 32   # 배치 사이즈 - 파라미터를 몇 개의 데이터마다 업데이트할지 설정. 얘도 성능과 연관 있음\n",
    "\n",
    "# 변수\n",
    "N_TRAIN = train_X.shape[0]  # train 데이터셋의 데이터 개수\n",
    "N_TEST = test_X.shape[0]    # test 데이터셋의 데이터 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X, y 전처리, tf.Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 전처리 - scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_X)\n",
    "X_test = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 구현\n",
    "# drop_remainder=True: 배치 사이즈보다 덜한 나머지는 버려라(제공하지 말아라) - 학습 효율을 위함\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, train_y)).shuffle(N_TRAIN).batch(N_BATCHS, drop_remainder=True)\n",
    "\n",
    "# batch size로 교차 검증하는 역할. 테스트 한 번만 하려면 batch size를 N_TEST로 주면 됨\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, test_y)).batch(N_BATCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification\n",
    "\n",
    "### Fashion MNIST(MNIST) Dataset - 다중분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋. \n",
    "이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 의류 품목을 나타낸다:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>그림</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "패션 MNIST와 손글씨 MNIST는  비교적 작기 때문에 알고리즘의 작동 여부를 확인하기 위해 사용되곤 하며 코드를 테스트하고 디버깅하는 용도로 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지는 28x28 크기의 넘파이 배열이고 픽셀 값은 0과 255 사이이다. *레이블*(label)은 0에서 9까지의 정수 배열이다. 아래 표는 이미지에 있는 의류의 **클래스**(class)를 나낸다.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>레이블</th>\n",
    "    <th>클래스</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trousers</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "각 이미지는 하나의 레이블에 매핑되어 있다. 데이터셋에 클래스 이름이 들어있지 않기 때문에 나중에 이미지를 출력할 때 사용하기 위해 별도의 변수를 만들어 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:13:37.059205Z",
     "start_time": "2021-04-14T09:13:37.050854Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위스콘신 유방암 데이터셋 - 이진분류 문제\n",
    "- 위스콘신 대학교에서 제공한 종양의 악성/양성여부 분류를 위한 데이터셋\n",
    "- Feature\n",
    "    - 종양에 대한 다양한 측정값들\n",
    "- Target의 class\n",
    "    - 0 - malignant(악성종양)\n",
    "    - 1 - benign(양성종양)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
